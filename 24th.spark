import org.apache.spark.sql.SparkSession

object ItemProcessing {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder()
      .appName("ItemProcessing")
      .master("local[*]")
      .getOrCreate()

    // Sample Item data
    val itemData = Map(
      "Ball" -> 10, "Ribbon" -> 50, "Box" -> 20,
      "Pen" -> 5, "Book" -> 8, "Dairy" -> 4, "Pin" -> 20
    )

    // Convert Item Map to RDD
    val itemRDD = spark.sparkContext.parallelize(itemData.toSeq)

    // i. Find how many partitions are created
    println(s"Number of partitions: ${itemRDD.getNumPartitions}")

    // ii. Display content of the RDD
    println("\nContent of RDD:")
    itemRDD.foreach(println)

    // iii. Display content of each partition separately
    println("\nContent of each partition:")
    itemRDD.glom().collect().zipWithIndex.foreach { case (part, index) =>
      println(s"Partition $index: ${part.mkString(", ")}")
    }

    spark.stop()
  }
}
